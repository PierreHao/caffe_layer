# Swish layer
1. Y = X * Sigmoid(X)
2. Better activate function than ReLU
